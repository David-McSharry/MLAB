{"cells": [{"cell_type": "markdown", "metadata": {}, "source": "\n# W1D3 - Build Your Own Backpropagation Framework\n\nToday you're going to build your very own system that can run the backpropagation algorithm in essentially the same way as PyTorch does. By the end of the day, you'll be able to train a multi-layer perceptron neural network using your own backprop system!\n\nThe main differences between the full PyTorch and our version are:\n\n- We will focus on CPU only, as all the ideas are the same on GPU.\n- We will use NumPy arrays internally instead of ATen, the C++ array type used by PyTorch. Backpropagation works independently of the array type.\n- A real `torch.Tensor` has about 700 fields and methods. We will only implement a subset that are particularly instructional and/or necessary to train the MLP.\n\n## Table of Contents\n\n- [Readings](#readings)\n- [Computing Gradients with Backpropagation](#computing-gradients-with-backpropagation)\n    - [Backward Functions](#backward-functions)\n    - [Backpropagation](#backpropagation)\n- [Static Typing In Python Crash Course](#static-typing-in-python-crash-course)\n- [Backward functions](#backward-functions)\n    - [Backward function of log](#backward-function-of-log)\n- [Backwards Functions of Two Tensors](#backwards-functions-of-two-tensors)\n    - [Broadcasting Rules](#broadcasting-rules)\n    - [Backward Function for Elementwise Multiply](#backward-function-for-elementwise-multiply)\n- [Autograd](#autograd)\n    - [Wrapping Arrays (Tensor)](#wrapping-arrays-tensor)\n    - [Recipe](#recipe)\n- [Registering backwards functions](#registering-backwards-functions)\n- [Tensors](#tensors)\n    - [requires_grad](#requiresgrad)\n- [Forward Pass: Building the Computational Graph](#forward-pass-building-the-computational-graph)\n- [Forward Pass - Generic Version](#forward-pass---generic-version)\n- [Backpropagation](#backpropagation-)\n    - [Topological Sort](#topological-sort)\n    - [The Actual Backprop Function](#the-actual-backprop-function)\n- [Filling out the Tensor class with forward and backward methods](#filling-out-the-tensor-class-with-forward-and-backward-methods)\n- [Non-Differentiable Functions](#non-differentiable-functions)\n- [Implementing `negative`](#implementing-negative)\n- [Implementing `exp`](#implementing-exp)\n- [Reshape](#reshape)\n- [Permute](#permute)\n- [Expand](#expand)\n- [Backwards Pass - Sum](#backwards-pass---sum)\n- [Backwards Pass - Indexing](#backwards-pass---indexing)\n- [Elementwise addition, subtract, true_divide](#elementwise-addition-subtract-truedivide)\n- [In-Place Operations](#in-place-operations)\n- [Mixed scalar-tensor operations](#mixed-scalar-tensor-operations)\n- [Splitting Gradients - elementwise maximum](#splitting-gradients---elementwise-maximum)\n- [Functional ReLU](#functional-relu)\n- [2D Matrix Multiply](#d-matrix-multiply)\n- [Build Your Own `nn.Parameter`](#build-your-own-nnparameter)\n- [Build Your Own `nn.Module`](#build-your-own-nnmodule)\n- [Build Your Own Linear Layer](#build-your-own-linear-layer)\n- [Build Your Own Cross-Entropy Loss](#build-your-own-cross-entropy-loss)\n- [Build Your Own `no_grad`](#build-your-own-nograd)\n- [Training Your Network](#training-your-network)\n    - [Training Loop](#training-loop)\n- [Bonus](#bonus)\n    - [In-Place Operation Warnings](#in-place-operation-warnings)\n    - [In-Place ReLU](#in-place-relu)\n    - [Backward for einsum](#backward-for-einsum)\n    - [Reuse of Module during forward](#reuse-of-module-during-forward)\n    - [ResNet Support](#resnet-support)\n    - [Central Difference Checking](#central-difference-checking)\n    - [Non-Differentiable Function Support](#non-differentiable-function-support)\n    - [Differentiation wrt Keyword Arguments](#differentiation-wrt-keyword-arguments)\n    - [torch.stack](#torchstack)\n\n## Readings\n\n- [Max's Extension of Chris Olah's \"Calculus on Computational Graphs: Backpropagation\"](https://witty-mirror-0a0.notion.site/Automatic-differentiation-f5f45f26ec47431fadbd67f831700d5c)\n\n## Computing Gradients with Backpropagation\n\nThis section will briefly review the backpropagation algorithm, but focus mainly on the concrete implementation in software.\n\nTo train a neural network, we want to know how the loss would change if we slightly adjust one of the learnable parameters.\n\nOne obvious and straightforward way to do this would be just to add a small value $\\epsilon$ to the parameter, and run the forward pass again. This is called *finite differences*, and the main issue is we need to run a forward pass for every single parameter that we want to adjust. This method is infeasible for large networks, but it's important to know as a way of sanity checking other methods.\n\nA second obvious way is to write out the function for the entire network, and then symbolically take the gradient to obtain a symbolic expression for the gradient. This also works and is another thing to check against, but the expression gets quite complicated.\n\nSuppose that you have some computation graph, and you want to determine the derivative of the some scalar loss L with respect to NumPy arrays a, b, and c:\n\n```mermaid\n\ngraph LR\n    a & b --> Mul1{Mul}\n    b & c --> Add1{Add}\n    Mul1 --> d --> Add2{Add}\n    Add1 --> e --> Add2\n    Add2 --> L\n```\n\nThis graph corresponds to the following Python:\n\n"}, {"cell_type": "code", "metadata": {}, "source": "d = a * b\ne = b + c\nL = d + e\n", "outputs": []}, {"cell_type": "markdown", "metadata": {}, "source": "\nThe goal of our system is that users can write ordinary looking Python code like this and have all the book-keeping needed to perform backpropagation happen behind the scenes. To do this, we're going to wrap each array and each function in special objects from our library that do the usual thing plus build up this graph structure that we need.\n\n### Backward Functions\n\nWe've drawn our computation graph from left to right and the arrows pointing to the right, so that in the forward pass, boxes to the right depend on boxes to the left. In the backwards pass, the opposite is true: the gradient of boxes on the left depends on the gradient of boxes on the right.\n\nWe're going to forbid any cycles in the graph to guarantee it's possible to do what we want, which is traverse the graph once from right to left. This means no in-place operations that modify memory. We can still write code that reuses variable names like `a = a + b`, but it's important to understand that the `a` on the left hand side is a separate instance of `Tensor` than the one on the right hand side.\n\nEach time we encounter an instance of function application, we can use the chain rule from calculus to proceed one step further to the left. For example, if we have `d = a * b`, then:\n\n$$\\frac{dL}{da} = \\frac{dL}{dd}\\frac{dd}{da} = \\frac{dL}{dd}b$$\n$$\\frac{dL}{db} = \\frac{dL}{dd}\\frac{dd}{db} = \\frac{dL}{dd}a$$\n\nIn other words, if we already know $\\frac{dL}{dd}$ and want to obtain $\\frac{dL}{da}$, then the function $f(x) = b * x$ will do the job for us. This function $f$ is telling us how \"sensitive\" $\\frac{dL}{da}$ is to small changes in `a`. We will write one of these \"backwards functions\" for each function and each input argument we want to support. To keep things simple for now, we will assume that the input arguments can be numbered by their position.\n\n### Backpropagation\n\nAfter all this setup, the actual backpropagation process becomes straightforward. First sort the nodes into a reverse [topological ordering](https://en.wikipedia.org/wiki/Topological_sorting) and then iterate over them and call each backward function exactly once. Because we visit the nodes in this special ordering, we've guaranteed that the argument $\\frac{dL}{d_{out}}$ that our function needs has been computed already and is available for use.\n\nAt the first (rightmost) node we visit, the argument to `backward()` will be just $\\frac{dL}{dL} = 1$.\n\nIt's important that the grads be accumulated instead of overwritten in a case like value $b$ which has two outgoing edges, since $dL/db$ will then be the sum of two terms. Since addition is commutative it doesn't matter whether we `backward()` the Mul or the Add that depend on $b$ first.\n\nAccumulating grads is also important for the case where you want to make multiple forward and backward calls before adjusting the weights. For example, if you want to have a batch size of 32 but only 8 inputs fit on your GPU, you can run 4 forward and backward calls before each call to the optimizer.\n\n## Static Typing In Python Crash Course\n\nStatic typing is optional in Python and represents a tradeoff: you spend more time writing type annotations, but then you can catch errors in your IDE instead of having to wait for tests to fail or a runtime exception.\n\nToday it's going to be particularly beneficial to you to use type annotations, because your code will have a variety of types and it's easy to mix them up. It's also good practice to annotate APIs that other developers will work with as a form of documentation.\n\nFor the most part, you can figure type annotations out just by looking at the provided example code. Here are some additional tips:\n\n- You can enable strict type checking in `.vscode/settings.json` by setting `\"python.analysis.typeCheckingMode\"` to `basic` or `strict`.\n- VS Code shows type errors in the \"Problems\" tab.\n- Hover over a symbol with the mouse in VS Code to see what type the checker thinks something is. If it already inferred the type correctly, there's probably no benefit to adding an annotation.\n- If you want to name a type that hasn't been defined yet, just write the type's name as a string. For example list['CustomType'] works even if CustomType is defined later in the file.\n- Since Python 3.9, you can call the type of a dict with s tring keys and float values `dict[str, float]`.\n- Similarly `list[int]` is the type of a list of int, or `tuple[float, float]` for a 2-tuple of floats.\n- The standard library `typing` module has some useful types:\n    - `Union[type1, type2]` means either type1 or type2.\n    - `Optional[type1]` is another way to write `Union[type1, None]`\n    - `Any` means the object can legally have any methods or fields. This is different from `object`, which is the base class for everything and has no methods or fields.\n    - `Callable[[argtype1, argtype2], returntype]` is useful if you want to pass a function as an argument.\n    - If you want to type a variable number of arguments, just write the type of one of them: `def forward(self, *args: float)` takes zero or more floats as arguments.\n\n\n\n"}, {"cell_type": "code", "metadata": {}, "source": "import os\nimport time\nfrom collections import defaultdict\nfrom dataclasses import dataclass\nfrom typing import Any, Callable, Iterable, Iterator, Optional, Protocol, Union\nimport numpy as np\nfrom matplotlib import pyplot as plt\nimport w1d3_test\nimport w1d3_utils\n\nMAIN = __name__ == \"__main__\"\nIS_CI = os.getenv(\"IS_CI\")\nArr = np.ndarray\ngrad_tracking_enabled = True\n\n", "outputs": []}, {"cell_type": "markdown", "metadata": {}, "source": "\n## Backward functions\n\nDuring backpropagation, for each forward function in our computational graph we need to find the partial derivative of the output with respect to each of its inputs. Each partial is then multiplied by the gradient of the loss with respect to the forward functions output (`grad_out`) to find the gradient of the loss with respect to each input. We'll handle these calculations using backward functions.\n\n### Backward function of log\n\nConsider this computation graph where L is the loss:\n\n```mermaid\n\ngraph LR\n    a --> Log1 --> b --> Log2 --> c --> Sum --> L\n```\n\n`log_back` will be called twice during backpropagation:\n\n- $log\\_back(\\partial L / \\partial c, c, b)$ is the first call at node Log2 and should return $\\partial L / \\partial b$\n- $log\\_back(\\partial L / \\partial b, b, a)$ is the second call at node Log1 and should return $\\partial L / \\partial a$\n\nImplement `log_back` so it does the right thing.\n\n<details>\n\n<summary>Solution - log_back</summary>\n\nConsider the first call and the first scalar element of `c`, which is equal to the log of the first scalar element of `b`. By the chain rule:\n\n$$ \\frac{dL}{db} = \\frac{dL}{dc} \\frac{dc}{db} = \\frac{dL}{dc} \\frac{d(log(b))}{db} = \\frac{dL}{dc} \\frac{1}{b}$$\n\nSince `log` operates elementwise, the gradient is just the same as doing this derivative elementwise. All we need to do is divide `grad_out` by the input argument `x`.\n\n</details>\n\nNote in this case you don't need to use the `out` argument - we'll see examples where it's useful later. Also don't worry about division by zero or other edge cases - the goal here is just to see how the pieces of the system fit together.\n\n\n"}, {"cell_type": "code", "metadata": {}, "source": "def log_back(grad_out: Arr, out: Arr, x: Arr) -> Arr:\n    \"\"\"Backwards function for f(x) = log(x)\n\n    grad_out: Gradient of some loss wrt out\n    out: the output of np.log(x). Provided as an optimization in case it's cheaper to express the gradient in terms of the output.\n    x: the input of np.log.\n\n    Return: gradient of the given loss wrt x\n    \"\"\"\n    pass\n\n\nif MAIN:\n    w1d3_test.test_log_back(log_back)\n\n", "outputs": []}, {"cell_type": "markdown", "metadata": {}, "source": "\n## Backwards Functions of Two Tensors\n\nNow we'll implement backward functions for multiple tensors. To do so, we first need to understand broadcasting.\n\n### Broadcasting Rules\n\nBoth NumPy and PyTorch have the same rules for broadcasting:\n\n- Dimensions of length 1 can be expanded to any length.\n- Additional dimensions of any length can be prepended to the front of the shape.\n\nWe will handle two situations where broadcasting can occur:\n\n- A binary operation between arrays of two different shapes: both are broadcasted to a common shape.\n- An explicit call to an expansion function. We will be implementing the functionality of `torch.expand` using `np.broadcast_to` as the underlying function.\n\nIn either case, backpropagation has to do the same thing: the grad with respect to an input element has to be the sum of each position where that input element was used in the output.\n\nImplement the `unbroadcast` helper function.\n\n<details>\n\n<summary>I'm confused about implementing unbroadcast!</summary>\n\nUnbroadcast has to do two things:\n\n- Sum and remove dimensions that were prepended to the front of the original shape.\n- Sum dimensions that were originally 1 back to the size 1 (using keepdims=True).\n\nIt's easiest to do the two tasks in that order, since after removing the additional dimensions, the shapes will have an equal number of dimensions.\n\n</details>\n\n\n"}, {"cell_type": "code", "metadata": {}, "source": "def unbroadcast(broadcasted: Arr, original: Arr) -> Arr:\n    \"\"\"Sum 'broadcasted' until it has the shape of 'original'.\n\n    broadcasted: An array that was formerly of the same shape of 'original' and was expanded by broadcasting rules.\n    \"\"\"\n    pass\n\n\nif MAIN:\n    w1d3_test.test_unbroadcast(unbroadcast)\n\n", "outputs": []}, {"cell_type": "markdown", "metadata": {}, "source": "\n### Backward Function for Elementwise Multiply\n\nFunctions that are differentiable with respect to more than one input tensor are straightforward given that we already know how to handle broadcasting.\n\n- We're going to have two backwards functions, one for each input argument.\n- If the input arguments were broadcasted together to create a larger output, the incoming `grad_out` will be of the larger common broadcasted shape and we need to make use of `unbroadcast` from earlier to match the shape to the appropriate input argument.\n- We'll want our backward function to work when one of the inputs is an float. We won't need to calculate the grad_in with respect to floats, so we only need to consider when y is an float for `multiply_back0` and when x is an float for `multiplyback1`.\n\n\n\n"}, {"cell_type": "code", "metadata": {}, "source": "def multiply_back0(grad_out: Arr, out: Arr, x: Arr, y: Union[Arr, float]) -> Arr:\n    \"\"\"Backwards function for x * y wrt argument 0 aka x.\"\"\"\n    pass\n\n\ndef multiply_back1(grad_out: Arr, out: Arr, x: Union[Arr, float], y: Arr) -> Arr:\n    \"\"\"Backwards function for x * y wrt argument 1 aka y.\"\"\"\n    pass\n\n\nif MAIN:\n    w1d3_test.test_multiply_back(multiply_back0, multiply_back1)\n    w1d3_test.test_multiply_back_float(multiply_back0, multiply_back1)\n\n", "outputs": []}, {"cell_type": "markdown", "metadata": {}, "source": "\nNow we'll use our backward functions to do backpropagation manually, for the following computational graph:\n\n\n```mermaid\n\ngraph LR\n    a --> prod1[*] --> d --> prod2[*] --> f --> log1[Log] --> g\n    b --> prod1\n    c --> log2[Log] --> e --> prod2\n```\n\n\n\n"}, {"cell_type": "code", "metadata": {}, "source": "def forward_and_back(a: Arr, b: Arr, c: Arr) -> tuple[Arr, Arr, Arr]:\n    \"\"\"\n    Calculates the output of the computational graph above (g), then backpropogates the gradients and returns dg/da, dg/db, and dg/dc\n    \"\"\"\n    d = a * b\n    e = np.log(c)\n    f = d * e\n    g = np.log(f)\n    pass\n\n\nif MAIN:\n    w1d3_test.test_forward_and_back(forward_and_back)\n\n", "outputs": []}, {"cell_type": "markdown", "metadata": {}, "source": "\n## Autograd\n\nNow, rather than figuring out which backward functions to call, in what order, and what their inputs should be, we'll write code that takes care of that for us. We'll implement this with a few major components:\n\n- Tensor\n- Recipe\n- wrap_forward_fn\n\n### Wrapping Arrays (Tensor)\n\nWe're going to wrap each array with a wrapper object from our library which we'll call `Tensor` because it's going to behave similarly to a `torch.Tensor`.\n\nEach Tensor that is created by one of our forward functions will have a `Recipe`, which tracks the extra information need to run backpropagation.\n\n`wrap_forward_fn` will take a forward function and return a new forward function that does the same thing while recording the info we need to do backprop in the `Recipe`.\n\n### Recipe\n\nLet's start by taking a look at `Recipe`.\n\n`@dataclass` is a handy class decorator that sets up an `__init__` function for the class that takes the provided attributes as arguments and sets them as you'd expect.\n\n\n\n"}, {"cell_type": "code", "metadata": {}, "source": "@dataclass(frozen=True)\nclass Recipe:\n    \"\"\"Extra information necessary to run backpropagation. You don't need to modify this.\"\"\"\n\n    func: Callable\n    \"The 'inner' NumPy function that does the actual forward computation.\"\n    args: tuple\n    \"The input arguments passed to func.\"\n    kwargs: dict[str, Any]\n    \"Keyword arguments passed to func. To keep things simple today, we aren't going to backpropagate with respect to these.\"\n    parents: dict[int, \"Tensor\"]\n    \"Map from positional argument index to the Tensor at that position, in order to be able to pass gradients back along the computational graph.\"\n\n", "outputs": []}, {"cell_type": "markdown", "metadata": {}, "source": "\n## Registering backwards functions\n\nThe `Recipe` takes care of tracking the forward functions in our computational graph, but we still need a way to find the backward function corresponding to a given forward function when we do backprop.\n\nThe implementation today can be done very simply. We won't support backprop wrt keyword arguments and will raise an exception if the user tries to pass a Tensor by keyword. You can remove this limitation later if you have time.\n\nWe do need to support functions with multiple positional arguments like multiplication so we'll also provide the positional argument index when setting and getting back_fns.\n\n\n\n"}, {"cell_type": "code", "metadata": {}, "source": "class BackwardFuncLookup:\n    def __init__(self) -> None:\n        pass\n\n    def add_back_func(self, forward_fn: Callable, arg_position: int, back_fn: Callable) -> None:\n        pass\n\n    def get_back_func(self, forward_fn: Callable, arg_position: int) -> Callable:\n        pass\n\n\nif MAIN:\n    w1d3_test.test_back_func_lookup(BackwardFuncLookup)\nBACK_FUNCS = BackwardFuncLookup()\nBACK_FUNCS.add_back_func(np.log, 0, log_back)\nBACK_FUNCS.add_back_func(np.multiply, 0, multiply_back0)\nBACK_FUNCS.add_back_func(np.multiply, 1, multiply_back1)\n\n", "outputs": []}, {"cell_type": "markdown", "metadata": {}, "source": "\n## Tensors\n\nOur Tensor object has these fields:\n\n- An `array` field of type `np.ndarray`.\n- A `requires_grad` field of type `bool`.\n- A `grad` field of the same size and type as the value.\n- A `recipe` field, as we've already seen.\n\n### requires_grad\nThe meaning of `requires_grad` is that when doing operations using this tensor, the recipe will be stored and it and any descendents will be included in the computational graph.\n\nNote that `requires_grad` does not mean that we will save the accumulated gradients to this tensor's `.grad` parameter when doing backprop: we will follow pytorch's implementation of backprop and only save gradients to leaf tensors (see `Tensor.is_leaf`, below).\n\nThere is a lot of repetitive boilerplate involved which we have done for you. You don't need to modify anything in this class: the methods here will delegate to functions that you will implement throughout the day.\n\n\n"}, {"cell_type": "code", "metadata": {}, "source": "class Tensor:\n    \"\"\"\n    A drop-in replacement for torch.Tensor supporting a subset of features.\n    \"\"\"\n\n    array: Arr\n    \"The underlying array. Can be shared between multiple Tensors.\"\n    requires_grad: bool\n    \"If True, calling functions or methods on this tensor will track relevant data for backprop.\"\n    grad: Optional[\"Tensor\"]\n    \"Backpropagation will accumulate gradients into this field.\"\n    recipe: Optional[Recipe]\n    \"Extra information necessary to run backpropagation.\"\n\n    def __init__(self, array: Union[Arr, list], requires_grad=False):\n        self.array = array if isinstance(array, Arr) else np.array(array)\n        self.requires_grad = requires_grad\n        self.grad = None\n        self.recipe = None\n        \"If not None, this tensor's array was created via recipe.func(*recipe.args, **recipe.kwargs).\"\n\n    def __neg__(self) -> \"Tensor\":\n        return negative(self)\n\n    def __add__(self, other) -> \"Tensor\":\n        return add(self, other)\n\n    def __radd__(self, other) -> \"Tensor\":\n        return add(other, self)\n\n    def __sub__(self, other) -> \"Tensor\":\n        return subtract(self, other)\n\n    def __rsub__(self, other):\n        return subtract(other, self)\n\n    def __mul__(self, other) -> \"Tensor\":\n        return multiply(self, other)\n\n    def __rmul__(self, other):\n        return multiply(other, self)\n\n    def __truediv__(self, other):\n        return true_divide(self, other)\n\n    def __rtruediv__(self, other):\n        return true_divide(self, other)\n\n    def __matmul__(self, other):\n        return matmul(self, other)\n\n    def __rmatmul__(self, other):\n        return matmul(other, self)\n\n    def __eq__(self, other):\n        return eq(self, other)\n\n    def __repr__(self) -> str:\n        return f\"Tensor({repr(self.array)}, requires_grad={self.requires_grad})\"\n\n    def __len__(self) -> int:\n        if self.array.ndim == 0:\n            raise TypeError\n        return self.array.shape[0]\n\n    def __hash__(self) -> int:\n        return id(self)\n\n    def __getitem__(self, index) -> \"Tensor\":\n        return getitem(self, index)\n\n    def add_(self, other: \"Tensor\", alpha: float = 1.0) -> \"Tensor\":\n        add_(self, other, alpha=alpha)\n        return self\n\n    @property\n    def T(self) -> \"Tensor\":\n        return permute(self)\n\n    def item(self):\n        return self.array.item()\n\n    def sum(self, dim=None, keepdim=False):\n        return sum(self, dim=dim, keepdim=keepdim)\n\n    def log(self):\n        return log(self)\n\n    def exp(self):\n        return exp(self)\n\n    def reshape(self, new_shape):\n        return reshape(self, new_shape)\n\n    def expand(self, new_shape):\n        return expand(self, new_shape)\n\n    def permute(self, dims):\n        return permute(self, dims)\n\n    def maximum(self, other):\n        return maximum(self, other)\n\n    def relu(self):\n        return relu(self)\n\n    def argmax(self, dim=None, keepdim=False):\n        return argmax(self, dim=dim, keepdim=keepdim)\n\n    def uniform_(self, low: float, high: float) -> \"Tensor\":\n        self.array[:] = np.random.uniform(low, high, self.array.shape)\n        return self\n\n    def backward(self, end_grad: Union[Arr, \"Tensor\", None] = None) -> None:\n        if isinstance(end_grad, Arr):\n            end_grad = Tensor(end_grad)\n        return backprop(self, end_grad)\n\n    def size(self, dim: Optional[int] = None):\n        if dim is None:\n            return self.shape\n        return self.shape[dim]\n\n    @property\n    def shape(self):\n        return self.array.shape\n\n    @property\n    def ndim(self):\n        return self.array.ndim\n\n    @property\n    def is_leaf(self):\n        \"\"\"Same as https://pytorch.org/docs/stable/generated/torch.Tensor.is_leaf.html\"\"\"\n        if self.requires_grad and self.recipe and self.recipe.parents:\n            return False\n        return True\n\n    def __bool__(self):\n        if np.array(self.shape).prod() != 1:\n            raise RuntimeError(\"bool value of Tensor with more than one value is ambiguous\")\n        return bool(self.item())\n\n\ndef empty(*shape: int) -> Tensor:\n    \"\"\"Like torch.empty.\"\"\"\n    return Tensor(np.empty(shape))\n\n\ndef zeros(*shape: int) -> Tensor:\n    \"\"\"Like torch.zeros.\"\"\"\n    return Tensor(np.zeros(shape))\n\n\ndef arange(start: int, end: int, step=1) -> Tensor:\n    \"\"\"Like torch.arange(start, end).\"\"\"\n    return Tensor(np.arange(start, end, step=step))\n\n\ndef tensor(array: Arr, requires_grad=False) -> Tensor:\n    \"\"\"Like torch.tensor.\"\"\"\n    return Tensor(array, requires_grad=requires_grad)\n\n", "outputs": []}, {"cell_type": "markdown", "metadata": {}, "source": "\n## Forward Pass: Building the Computational Graph\n\nLet's start with a simple case: our `log` function. Our `log` function must do the following:\n\n- Call `np.log(tensor.array)` to obtain an output array.\n- Create a new `Tensor` containing the output.\n- If grad tracking is enabled globally AND (the input requires grad, OR has a recipe), then the output requires grad and we fill out the recipe of our output. Note that since log has a single argument, `recipe.parents` will be a dict with a single integer key `0`.\n\nLater we'll redo this in a generic and reusable way, but for now just get it working.\n\n\n"}, {"cell_type": "code", "metadata": {}, "source": "def log_forward(x: Tensor) -> Tensor:\n    pass\n\n\nif MAIN:\n    log = log_forward\n    w1d3_test.test_log(Tensor, log_forward)\n    w1d3_test.test_log_no_grad(Tensor, log_forward)\n    a = Tensor([1], requires_grad=True)\n    grad_tracking_enabled = False\n    b = log_forward(a)\n    grad_tracking_enabled = True\n    assert not b.requires_grad, \"should not require grad if grad tracking globally disabled\"\n    assert b.recipe is None, \"should not create recipe if grad tracking globally disabled\"\n\n", "outputs": []}, {"cell_type": "markdown", "metadata": {}, "source": "\nNow let's do the same for multiply, to see how to handle functions with multiple arguments. There are a few differences:\n\n- The actual function to be called\n- The multiple positional input arguments that need to be recorded in the recipe as arguments and the Tensor args as parents\n- The possibility that one of the inputs may be an int\n\n\n\n"}, {"cell_type": "code", "metadata": {}, "source": "def multiply_forward(a: Union[Tensor, int], b: Union[Tensor, int]) -> Tensor:\n    assert isinstance(a, Tensor) or isinstance(b, Tensor)\n    pass\n\n\nif MAIN:\n    multiply = multiply_forward\n    w1d3_test.test_multiply(Tensor, multiply_forward)\n    w1d3_test.test_multiply_no_grad(Tensor, multiply_forward)\n    w1d3_test.test_multiply_float(Tensor, multiply_forward)\n    a = Tensor([2], requires_grad=True)\n    b = Tensor([3], requires_grad=True)\n    grad_tracking_enabled = False\n    b = multiply_forward(a, b)\n    grad_tracking_enabled = True\n    assert not b.requires_grad, \"should not require grad if grad tracking globally disabled\"\n    assert b.recipe is None, \"should not create recipe if grad tracking globally disabled\"\n\n", "outputs": []}, {"cell_type": "markdown", "metadata": {}, "source": "\n## Forward Pass - Generic Version\n\nAll our forward functions are going to look extremely similar to `log_forward` and `multiply_forward`.\n\nImplement the higher order function `wrap_forward_fn` that takes a `Arr -> Arr` function and returns a `Tensor -> Tensor` function. In other words, `wrap_forward_fn(np.log)` should evaluate to a callable that does the same thing as your `log_forward`.\n\n\n"}, {"cell_type": "code", "metadata": {}, "source": "def wrap_forward_fn(numpy_func: Callable, is_differentiable=True) -> Callable:\n    \"\"\"\n    numpy_func: function. It takes any number of positional arguments, some of which may be NumPy arrays, and any number of keyword arguments which we aren't allowing to be NumPy arrays at present. It returns a single NumPy array.\n    is_differentiable: if True, numpy_func is differentiable with respect to some input argument, so we may need to track information in a Recipe. If False, we definitely don't need to track information.\n\n    Return: function. It has the same signature as numpy_func, except wherever there was a NumPy array, this has a Tensor instead.\n    \"\"\"\n\n    def tensor_func(*args: Any, **kwargs: Any) -> Tensor:\n        pass\n\n    return tensor_func\n\n\nlog = wrap_forward_fn(np.log)\nmultiply = wrap_forward_fn(np.multiply)\nif MAIN:\n    w1d3_test.test_log(Tensor, log)\n    w1d3_test.test_log_no_grad(Tensor, log)\n    w1d3_test.test_multiply(Tensor, multiply)\n    w1d3_test.test_multiply_no_grad(Tensor, multiply)\n    w1d3_test.test_multiply_float(Tensor, multiply)\n    try:\n        log(x=Tensor([100]))\n    except Exception as e:\n        print(\"Got a nice exception as intended:\")\n        print(e)\n    else:\n        assert False, \"Passing tensor by keyword should raise some informative exception.\"\n\n", "outputs": []}, {"cell_type": "markdown", "metadata": {}, "source": "\n## Backpropagation\n\nNow all the pieces are in place to implement backpropagation. We need to:\n\n- Loop over the nodes from right to left. At each node:\n    - Call the backward function to transform the grad wrt output to the grad wrt input.\n    - If the node is a leaf, write the grad to the grad field.\n    - Otherwise, accumulate the grad into temporary storage.\n\n### Topological Sort\n\nAs part of backprop, we need to sort the nodes of our graph so we can traverse the graph in the appropriate order.\n\nWrite a general function `topological_sort` that return a list of node's descendants in topological order (beginning with the furthest descentents, ending with the starting node) using [depth-first search](https://en.wikipedia.org/wiki/Topological_sorting).\n\nFirst we'll define a couple protocol classes so that we can write `topological_sort` so that it generalize in a predictable way. We should write it in such a way that it can work with any pair of compatible Node/ChildrenGetters that follow the given protocol. You do not need to modify the Protocol classes.\n\n\n"}, {"cell_type": "code", "metadata": {}, "source": "class Node(Protocol):\n    \"\"\"\n    A protocol defining the Node's interface in topological sort. Any object will do!\n    \"\"\"\n\n\nclass ChildrenGetter(Protocol):\n    \"\"\"A protocol defining the get_children_fns passed to topological sort, to get the node's children\"\"\"\n\n    def __call__(self, node: Any) -> list[Any]:\n        \"\"\"Get the given node's children, returning a list of nodes\"\"\"\n        ...\n\n\ndef topological_sort(node: Node, get_children_fn: ChildrenGetter) -> list[Any]:\n    \"\"\"\n    Return a list of node's descendants in reverse topological order from future to past.\n    \"\"\"\n    pass\n\n\nif MAIN:\n    w1d3_test.test_topological_sort_linked_list(topological_sort)\n    w1d3_test.test_topological_sort_branching(topological_sort)\n    w1d3_test.test_topological_sort_rejoining(topological_sort)\n    w1d3_test.test_topological_sort_cyclic(topological_sort)\n\n", "outputs": []}, {"cell_type": "markdown", "metadata": {}, "source": "\nNow using your `topological_sort` write `sorted_computation_graph`, which returns the nodes in your computational graph in the order you need for backprop.\n\n\n"}, {"cell_type": "code", "metadata": {}, "source": "def sorted_computational_graph(node: Tensor) -> list[Tensor]:\n    \"\"\"\n    For a given tensor, return a list of Tensors that make up the nodes of the given Tensor's computational graph, in reverse topological order\n    \"\"\"\n    pass\n\n\nif MAIN:\n    a = Tensor([1], requires_grad=True)\n    b = Tensor([2], requires_grad=True)\n    c = Tensor([3], requires_grad=True)\n    d = a * b\n    e = c.log()\n    f = d * e\n    g = f.log()\n    name_lookup = {a: \"a\", b: \"b\", c: \"c\", d: \"d\", e: \"e\", f: \"f\", g: \"g\"}\n    print([name_lookup[t] for t in sorted_computational_graph(g)])\n\n", "outputs": []}, {"cell_type": "markdown", "metadata": {}, "source": "\n### The Actual Backprop Function\n\nNow we're really ready for backprop!\n\n\n"}, {"cell_type": "code", "metadata": {}, "source": "def backprop(end_node: Tensor, end_grad: Optional[Tensor] = None) -> None:\n    \"\"\"Accumulate gradients in the grad field of each leaf node.\n\n    tensor.backward() is equivalent to backprop(tensor).\n\n    end_node: the rightmost node in the computation graph. If it contains more than one element, end_grad must be provided.\n    end_grad: A tensor of the same shape as end_node. Set to 1 if not specified and end_node has only one element.\n    \"\"\"\n    pass\n\n\nif MAIN:\n    w1d3_test.test_backprop(Tensor)\n    w1d3_test.test_backprop_branching(Tensor)\n    w1d3_test.test_backprop_float_arg(Tensor)\n    w1d3_test.test_backprop_requires_grad_false(Tensor)\n\n", "outputs": []}, {"cell_type": "markdown", "metadata": {}, "source": "\n## Filling out the Tensor class with forward and backward methods\n\nCongrats on implementing backprop! The next thing we'll do is write implement a bunch of backward functions that we need to train our model at the end of the day, as well as ones that cover interesting cases.\n\n## Non-Differentiable Functions\n\nFor functions like `torch.argmax` or `torch.eq`, there's no sensible way to define gradients with respect to the input tensor. For these, we will still use `wrap_forward_fn` because we still need to unbox the arguments and box the result, but by passing `is_differentiable=False` we can avoid doing any unnecessary computation.\n\n\n"}, {"cell_type": "code", "metadata": {}, "source": "def _argmax(x: Arr, dim=None, keepdim=False):\n    \"\"\"Like torch.argmax.\"\"\"\n    return np.argmax(x, axis=dim, keepdims=keepdim)\n\n\nargmax = wrap_forward_fn(_argmax, is_differentiable=False)\neq = wrap_forward_fn(np.equal, is_differentiable=False)\nif MAIN:\n    a = Tensor([1.0, 0.0, 3.0, 4.0], requires_grad=True)\n    b = a.argmax()\n    assert not b.requires_grad\n    assert b.recipe is None\n    assert b.item() == 3\n\n", "outputs": []}, {"cell_type": "markdown", "metadata": {}, "source": "\n## Implementing `negative`\n\n`torch.negative` just performs `-x` elementwise. Make your own version `negative` using `wrap_forward_fn`.\n\n\n"}, {"cell_type": "code", "metadata": {}, "source": "def negative_back(grad_out: Arr, out: Arr, x: Arr) -> Arr:\n    \"\"\"Backward function for f(x) = -x elementwise.\"\"\"\n    pass\n\n\nnegative = wrap_forward_fn(np.negative)\nBACK_FUNCS.add_back_func(np.negative, 0, negative_back)\nif MAIN:\n    w1d3_test.test_negative_back(Tensor)\n\n", "outputs": []}, {"cell_type": "markdown", "metadata": {}, "source": "\n## Implementing `exp`\n\nMake your own version of `torch.exp`. The backward function should express the result in terms of the `out` parameter - this more efficient than expressing it in terms of `x`.\n\n\n"}, {"cell_type": "code", "metadata": {}, "source": "def exp_back(grad_out: Arr, out: Arr, x: Arr) -> Arr:\n    pass\n\n\nexp = wrap_forward_fn(np.exp)\nBACK_FUNCS.add_back_func(np.exp, 0, exp_back)\nif MAIN:\n    w1d3_test.test_exp_back(Tensor)\n\n", "outputs": []}, {"cell_type": "markdown", "metadata": {}, "source": "\n## Reshape\n\n`reshape` is a bit more complicated than the many functions we've dealt with so far: there is an additional positional argument `new_shape`. Since it's not a `Tensor`, we don't need to think about differentiating with respect to it.\n\nDepending how you wrote `wrap_forward_fn` and `backprop`, you might need to go back and adjust them to handle this. Or, you might just have to implement `reshape_back` and everything will work.\n\nNote that the output is a different shape than the input, but this doesn't introduce any additional complications.\n\n<details>\n\n<summary>I'm confused about the implementation of reshape_back!</summary>\n\nThe invariant is that the `grad_out` should always be the same shape as `x`. Reshape is elementwise (none of the individual scalars interact with each other), so we just need to reshape `grad` into the same shape as `x` for everything to \"line up\".\n\n</details>\n\n\n"}, {"cell_type": "code", "metadata": {}, "source": "def reshape_back(grad_out: Arr, out: Arr, x: Arr, new_shape: tuple) -> Arr:\n    pass\n\n\nreshape = wrap_forward_fn(np.reshape)\nBACK_FUNCS.add_back_func(np.reshape, 0, reshape_back)\nif MAIN:\n    w1d3_test.test_reshape_back(Tensor)\n\n", "outputs": []}, {"cell_type": "markdown", "metadata": {}, "source": "\n## Permute\n\nIn NumPy, the equivalent of `torch.permute` is called `np.transpose`, so we will wrap that.\n\n<details>\n\n<summary>I'm confused about the implementation of permute_back!</summary>\n\nThe gradients are in permuted positions, and we want to line them up with the original positions. This means we need to compute a permutation that is the inverse of the forward permutation.\n\n</details>\n\n<details>\n\n<summary>I'm still confused about permute_back!</summary>\n\nCompute the inverse permutation with `np.argsort(axes)` and then apply it with another `np.transpose`.\n\n</details>\n\n\n"}, {"cell_type": "code", "metadata": {}, "source": "def permute_back(grad_out: Arr, out: Arr, x: Arr, axes: tuple) -> Arr:\n    pass\n\n\nBACK_FUNCS.add_back_func(np.transpose, 0, permute_back)\npermute = wrap_forward_fn(np.transpose)\nif MAIN:\n    w1d3_test.test_permute_back(Tensor)\n\n", "outputs": []}, {"cell_type": "markdown", "metadata": {}, "source": "\n## Expand\n\nImplement your version of `torch.expand`. The backward function should just call `unbroadcast`.\n\n\n"}, {"cell_type": "code", "metadata": {}, "source": "def expand_back(grad_out: Arr, out: Arr, x: Arr, new_shape: tuple) -> Arr:\n    pass\n\n\ndef _expand(x: Arr, new_shape) -> Arr:\n    \"\"\"Like torch.expand, calling np.broadcast_to internally.\n\n    Note torch.expand supports -1 for a dimension size meaning \"don't change the size\".\n    np.broadcast_to does not natively support this.\n    \"\"\"\n    pass\n\n\nexpand = wrap_forward_fn(_expand)\nBACK_FUNCS.add_back_func(_expand, 0, expand_back)\nif MAIN:\n    w1d3_test.test_expand(Tensor)\n    w1d3_test.test_expand_negative_length(Tensor)\n\n", "outputs": []}, {"cell_type": "markdown", "metadata": {}, "source": "\n## Backwards Pass - Sum\n\nThe output can also be smaller than the input, such as when calling `torch.sum`. Implement your own `torch.sum` and `sum_back`.\n\n<details>\n\n<summary>I'm confused about the implementation of sum_back!</summary>\n\nFor a given element of `grad_out`, increasing any of the contributing inputs by `dx` also increases the sum by `dx` and increasing any other input doesn't affect the sum.\n\nSo there's no multiplication required here, just reshaping and broadcasting `grad_out` so that each element of `grad_out` is matched up with every contributing input element.\n\n</details>\n\n<details>\n\n<summary>I'm still confused about the implementation of sum_back!</summary>\n\nConsider the keepdim=True case first. The shape of grad_out is the same as the shape of x, except it's 1 in each dim that was summed out. That 1-length dim just needs to be copied, which is just a broadcasting operation.\n\nNow consider the keepdim=False case. We can reshape grad_out to the shape it would've been if keepdim=True, and then we've simplified our problem to the first case. Note that our reshape has to be a literal `reshape` call and not a broadcast, because broadcast can only prepend new axes and our new axes can be anywhere in the shape.\n</details>\n\n\n\n"}, {"cell_type": "code", "metadata": {}, "source": "def sum_back(grad_out: Arr, out: Arr, x: Arr, dim=None, keepdim=False):\n    pass\n\n\ndef _sum(x: Arr, dim=None, keepdim=False) -> Arr:\n    \"\"\"Like torch.sum, calling np.sum internally.\"\"\"\n    pass\n\n\nsum = wrap_forward_fn(_sum)\nBACK_FUNCS.add_back_func(_sum, 0, sum_back)\nif MAIN:\n    w1d3_test.test_sum_keepdim_false(Tensor)\n    w1d3_test.test_sum_keepdim_true(Tensor)\n    w1d3_test.test_sum_dim_none(Tensor)\n\n", "outputs": []}, {"cell_type": "markdown", "metadata": {}, "source": "\n## Backwards Pass - Indexing\n\nIn its full generality, indexing a `torch.Tensor` is really complicated and there are quite a few cases to handle separately.\n\nWe only need two cases today:\n\n- The index is an integer or tuple of integers.\n- The index is a tuple of (array or Tensor) representing coordinates. Each array is 1D and of equal length. Some coordinates may be repeated. This is [Integer array indexing](https://numpy.org/doc/stable/user/basics.indexing.html#integer-array-indexing).\n    - For example, to select the five elements at (0, 0), (1,0), (0, 1), (1, 2), and (0, 0), the index would be the tuple `(np.array([0, 1, 0, 1, 0]), np.array([0, 0, 1, 2, 0]))`.\n\n<details>\n\n<summary>I'm confused about the implementation of getitem_back!</summary>\n\nIf no coordinates were repeated, we could just assign the grad for each input element to be the grad at the corresponding output position, or 0 if that input element didn't appear.\n\nBecause of the potential for repeat coordinates, we need to sum the grad from each corresponding output position.\n\nInitialize an array of zeros of the same shape as x, and then write in the appropriate elements using [np.add.at](https://numpy.org/doc/stable/reference/generated/numpy.ufunc.at.html)\n\n</details>\n\n<details>\n\n<summary>I'm confused about an IndexError I'm getting in forward!</summary>\n\nIf you're seeing the message \"IndexError: only integers, slices (`:`), ellipsis (`...`), numpy.newaxis (`None`) and integer or boolean arrays are valid indices\", then possibly you're trying to index a NumPy array using a tuple of Tensors, which NumPy doesn't know how to do.\n\nNormally, the Tensor would have been unboxed already by the time `_getitem` is called, but if you did a check like `isinstance(arg, Tensor)` then a tuple[Tensor] doesn't meet this criteria.\n\nThe simplest fix is just to unbox it manually within `_getitem` as this is a special case scenario anyway, but you could also modify your forward wrapper to handle this.\n\n</details>\n\n\n"}, {"cell_type": "code", "metadata": {}, "source": "Index = Union[int, tuple[int, ...], tuple[Arr], tuple[Tensor]]\n\n\ndef _getitem(x: Arr, index: Index) -> Arr:\n    \"\"\"Like x[index] when x is a torch.Tensor.\"\"\"\n    pass\n\n\ndef getitem_back(grad_out: Arr, out: Arr, x: Arr, index: Index):\n    \"\"\"Backwards function for _getitem.\n\n    Hint: use np.add.at(a, indices, b)\n    \"\"\"\n    pass\n\n\ngetitem = wrap_forward_fn(_getitem)\nBACK_FUNCS.add_back_func(_getitem, 0, getitem_back)\nif MAIN:\n    w1d3_test.test_getitem_int(Tensor)\n    w1d3_test.test_getitem_tuple(Tensor)\n    w1d3_test.test_getitem_integer_array(Tensor)\n    w1d3_test.test_getitem_integer_tensor(Tensor)\n\n", "outputs": []}, {"cell_type": "markdown", "metadata": {}, "source": "\n## Elementwise addition, subtract, true_divide\n\nThese are exactly analogous to the multiply case. Note that Python and NumPy have the notion of \"floor division\", which is a truncating integer division as in `7 // 3 = 2`. You can ignore floor division: - we only need the usual floating point division which is called \"true division\".\n\nUse lambda functions to define and register the backward functions each in one line.\n\n\n"}, {"cell_type": "code", "metadata": {}, "source": "add = wrap_forward_fn(np.add)\nsubtract = wrap_forward_fn(np.subtract)\ntrue_divide = wrap_forward_fn(np.true_divide)\n\"TODO: YOUR CODE HERE\"\nif MAIN:\n    w1d3_test.test_add_broadcasted(Tensor)\n    w1d3_test.test_subtract_broadcasted(Tensor)\n    w1d3_test.test_truedivide_broadcasted(Tensor)\n\n", "outputs": []}, {"cell_type": "markdown", "metadata": {}, "source": "\n## In-Place Operations\n\nSupporting in-place operations introduces substantial complexity and generally doesn't help performance that much. The problem is that if any of the inputs used in the backward function have been modified in-place since the forward pass, then the backward function will incorrectly calculate using the modified version.\n\nPyTorch will warn you when this causes a problem with the error \"RuntimeError: a leaf Variable that requires grad is being used in an in-place operation.\".\n\nYou can implement the warning in the bonus section but for now your system will silently compute the wrong gradients - user beware!\n\n\n"}, {"cell_type": "code", "metadata": {}, "source": "def add_(x: Tensor, other: Tensor, alpha: float = 1.0) -> Tensor:\n    \"\"\"Like torch.add_. Compute x += other * alpha in-place and return tensor.\"\"\"\n    np.add(x.array, other.array * alpha, out=x.array)\n    return x\n\n\ndef safe_example():\n    \"\"\"This example should work properly.\"\"\"\n    a = Tensor([0.0, 1.0, 2.0, 3.0], requires_grad=True)\n    b = Tensor([2.0, 3.0, 4.0, 5.0], requires_grad=True)\n    a.add_(b)\n    c = a * b\n    c.sum().backward()\n    assert a.grad is not None and np.allclose(a.grad.array, [2.0, 3.0, 4.0, 5.0])\n    assert b.grad is not None and np.allclose(b.grad.array, [2.0, 4.0, 6.0, 8.0])\n\n\ndef unsafe_example():\n    \"\"\"This example is expected to compute the wrong gradients.\"\"\"\n    a = Tensor([0.0, 1.0, 2.0, 3.0], requires_grad=True)\n    b = Tensor([2.0, 3.0, 4.0, 5.0], requires_grad=True)\n    c = a * b\n    a.add_(b)\n    c.sum().backward()\n    if a.grad is not None and np.allclose(a.grad.array, [2.0, 3.0, 4.0, 5.0]):\n        print(\"Grad wrt a is OK!\")\n    else:\n        print(\"Grad wrt a is WRONG!\")\n    if b.grad is not None and np.allclose(b.grad.array, [0.0, 1.0, 2.0, 3.0]):\n        print(\"Grad wrt b is OK!\")\n    else:\n        print(\"Grad wrt b is WRONG!\")\n\n\nif MAIN:\n    safe_example()\n    unsafe_example()\n\n", "outputs": []}, {"cell_type": "markdown", "metadata": {}, "source": "\n## Mixed scalar-tensor operations\n\nYou may have been wondering why our `Tensor` class has to define both `__mul__` and `__rmul__` magic methods.\n\nWithout `__rmul__` defined, executing `2 * a` when `a` is a `Tensor` would try to call `2.__mul__(a)`, and the built-in class `int` would be confused about how to handle this.\n\nSince we have defined `__rmul__` for you at the start, and you implemented multiply to work with floats as arguments, the following should \"just work\".\n\n\n"}, {"cell_type": "code", "metadata": {}, "source": "if MAIN:\n    a = Tensor([0, 1, 2, 3], requires_grad=True)\n    (a * 2).sum().backward()\n    b = Tensor([0, 1, 2, 3], requires_grad=True)\n    (2 * b).sum().backward()\n    assert a.grad is not None\n    assert b.grad is not None\n    assert np.allclose(a.grad.array, b.grad.array)\n\n", "outputs": []}, {"cell_type": "markdown", "metadata": {}, "source": "\n## Splitting Gradients - elementwise maximum\n\nSince this is an elementwise function, we can think about the scalar case. For scalar $x$, $y$, the derivative for $max(x, y)$ wrt x is 1 when $x > y$ and 0 when $x < y$. What should happen when $x = y$?\n\n<details>\n\n<summary>Solution - derivative of maximum</summary>\n\n$max(x, x)$ is equivalent to the identity function, which has a derivative of 1 wrt x. The sum of our partial derivatives wrt x and y must also therefore total 1.\n\nPyTorch splits the derivative evenly between the two arguments. We will follow this behavior for compatibility, but it's just as legitimate to say it's 1 wrt x and 0 wrt y, or some other arbitrary combination that sums to one.\n</details>\n\n\n"}, {"cell_type": "code", "metadata": {}, "source": "def maximum_back0(grad_out: Arr, out: Arr, x: Arr, y: Arr):\n    \"\"\"Backwards function for max(x, y) wrt x.\"\"\"\n    pass\n\n\ndef maximum_back1(grad_out: Arr, out: Arr, x: Arr, y: Arr):\n    \"\"\"Backwards function for max(x, y) wrt y.\"\"\"\n    pass\n\n\nmaximum = wrap_forward_fn(np.maximum)\nBACK_FUNCS.add_back_func(np.maximum, 0, maximum_back0)\nBACK_FUNCS.add_back_func(np.maximum, 1, maximum_back1)\nif MAIN:\n    w1d3_test.test_maximum(Tensor)\n    w1d3_test.test_maximum_broadcasted(Tensor)\n\n", "outputs": []}, {"cell_type": "markdown", "metadata": {}, "source": "\n## Functional ReLU\n\nA simple and correct ReLU function can be defined in terms of your maximum function. Note the PyTorch version also supports in-place operation, which we are punting on for now.\n\nAgain, at $x = 0$ your derivative could reasonably be anything between 0 and 1 inclusive, but we've followed PyTorch in making it 0.5.\n\n\n"}, {"cell_type": "code", "metadata": {}, "source": "def relu(x: Tensor) -> Tensor:\n    \"\"\"Like torch.nn.function.relu(x, inplace=False).\"\"\"\n    pass\n\n\nif MAIN:\n    w1d3_test.test_relu(Tensor)\n\n", "outputs": []}, {"cell_type": "markdown", "metadata": {}, "source": "\n## 2D Matrix Multiply\n\nImplement your version of `torch.matmul`, restricting it to the simpler case where both inputs are 2D.\n\n<details>\n\n<summary>I'm confused about matmul2d_back!</summary>\n\nTry working it out on paper, starting from a couple 2x2 matrices. Can you express the answer in terms of another matrix multiply and a transpose?\n\n</details>\n\n<details>\n\n<summary>I'm still confused about matmul2d_back!</summary>\n\nWith respect to x, it is `grad_out @ transpose(y)`.\nWith respect to y, it is `transpose(x) @ grad_out`.\n\n</details>\n\n\n"}, {"cell_type": "code", "metadata": {}, "source": "def _matmul2d(x: Arr, y: Arr) -> Arr:\n    \"\"\"Matrix multiply restricted to the case where both inputs are exactly 2D.\"\"\"\n    pass\n\n\ndef matmul2d_back0(grad_out: Arr, out: Arr, x: Arr, y: Arr) -> Arr:\n    pass\n\n\ndef matmul2d_back1(grad_out: Arr, out: Arr, x: Arr, y: Arr) -> Arr:\n    pass\n\n\nmatmul = wrap_forward_fn(_matmul2d)\nBACK_FUNCS.add_back_func(_matmul2d, 0, matmul2d_back0)\nBACK_FUNCS.add_back_func(_matmul2d, 1, matmul2d_back1)\nif MAIN:\n    w1d3_test.test_matmul2d(Tensor)\n\n", "outputs": []}, {"cell_type": "markdown", "metadata": {}, "source": "\n## Build Your Own `nn.Parameter`\n\nWe've now written enough backwards passes that we can go up a layer and write our own `nn.Parameter` and `nn.Module`.\n\nWe don't need much for `Parameter`. It is itself a `Tensor`, shares storage with the provided `Tensor` and requires_grad is `True` by default - that's it!\n\n\n"}, {"cell_type": "code", "metadata": {}, "source": "class Parameter(Tensor):\n    def __init__(self, tensor: Tensor, requires_grad=True):\n        \"\"\"Share the array with the provided tensor.\"\"\"\n        pass\n\n    def __repr__(self):\n        return f\"Parameter containing:\\n{super().__repr__()}\"\n\n\nif MAIN:\n    x = Tensor([1.0, 2.0, 3.0])\n    p = Parameter(x)\n    assert p.requires_grad\n    assert p.array is x.array\n    assert repr(p) == \"Parameter containing:\\nTensor(array([1., 2., 3.]), requires_grad=True)\"\n    x.add_(Tensor(np.array(2.0)))\n    assert np.allclose(\n        p.array, np.array([3.0, 4.0, 5.0])\n    ), \"in-place modifications to the original tensor should affect the parameter\"\n\n", "outputs": []}, {"cell_type": "markdown", "metadata": {}, "source": "\n## Build Your Own `nn.Module`\n\n`nn.Module` is like `torch.Tensor` in that it has a lot of functionality, most of which we don't care about today. We will just implement enough to get our network training.\n\nImplement the indicated methods.\n\nTip: you can bypass `__getattr__` by accessing `self.__dict__` inside a method.\n\n\n"}, {"cell_type": "code", "metadata": {}, "source": "class Module:\n    _modules: dict[str, \"Module\"]\n    _parameters: dict[str, Parameter]\n\n    def __init__(self):\n        pass\n\n    def modules(self):\n        \"\"\"Return the direct child modules of this module.\"\"\"\n        return self.__dict__[\"_modules\"].values()\n\n    def parameters(self, recurse: bool = True) -> Iterator[Parameter]:\n        \"\"\"Return an iterator over Module parameters.\n\n        recurse: if True, the iterator includes parameters of submodules, recursively.\n        \"\"\"\n        pass\n\n    def __setattr__(self, key: str, val: Any) -> None:\n        \"\"\"\n        If val is a Parameter or Module, store it in the appropriate _parameters or _modules dict.\n        Otherwise, call the superclass.\n        \"\"\"\n        pass\n\n    def __getattr__(self, key: str) -> Union[Parameter, \"Module\"]:\n        \"\"\"\n        If key is in _parameters or _modules, return the corresponding value.\n        Otherwise, raise KeyError.\n        \"\"\"\n        pass\n\n    def __call__(self, *args, **kwargs):\n        return self.forward(*args, **kwargs)\n\n    def forward(self):\n        raise NotImplementedError(\"Subclasses must implement forward!\")\n\n    def __repr__(self):\n        pass\n\n\nif MAIN:\n\n    class TestInnerModule(Module):\n        def __init__(self):\n            super().__init__()\n            self.param1 = Parameter(Tensor([1.0]))\n            self.param2 = Parameter(Tensor([2.0]))\n\n    class TestModule(Module):\n        def __init__(self):\n            super().__init__()\n            self.inner = TestInnerModule()\n            self.param3 = Parameter(Tensor([3.0]))\n\n    mod = TestModule()\n    assert list(mod.modules()) == [mod.inner]\n    assert list(mod.parameters()) == [\n        mod.param3,\n        mod.inner.param1,\n        mod.inner.param2,\n    ], \"parameters should come before submodule parameters\"\n    print(\"Manually verify that the repr looks reasonable:\")\n    print(mod)\n\n", "outputs": []}, {"cell_type": "markdown", "metadata": {}, "source": "\n## Build Your Own Linear Layer\n\nYou may have a `Linear` written already that you can adapt to use our own `Parameter`, `Module`, and `Tensor`. If your `Linear` used `einsum`, use a `matmul` instead. You can implement a backward function for `einsum` in the bonus section.\n\n\n"}, {"cell_type": "code", "metadata": {}, "source": "class Linear(Module):\n    weight: Parameter\n    bias: Optional[Parameter]\n\n    def __init__(self, in_features: int, out_features: int, bias=True):\n        \"\"\"A simple linear (technically, affine) transformation.\n\n        The fields should be named `weight` and `bias` for compatibility with PyTorch.\n        If `bias` is False, set `self.bias` to None.\n        \"\"\"\n        pass\n\n    def forward(self, x: Tensor) -> Tensor:\n        \"\"\"\n        x: shape (*, in_features)\n        Return: shape (*, out_features)\n        \"\"\"\n        pass\n\n    def extra_repr(self) -> str:\n        pass\n\n", "outputs": []}, {"cell_type": "markdown", "metadata": {}, "source": "\nNow we can define a MLP suitable for classifying MNIST, with zero PyTorch dependency!\n\n\n"}, {"cell_type": "code", "metadata": {}, "source": "class MLP(Module):\n    def __init__(self):\n        super().__init__()\n        self.linear1 = Linear(28 * 28, 64)\n        self.linear2 = Linear(64, 64)\n        self.output = Linear(64, 10)\n\n    def forward(self, x):\n        x = x.reshape((x.shape[0], 28 * 28))\n        x = relu(self.linear1(x))\n        x = relu(self.linear2(x))\n        x = self.output(x)\n        return x\n\n", "outputs": []}, {"cell_type": "markdown", "metadata": {}, "source": "\n## Build Your Own Cross-Entropy Loss\n\nMake use of your integer array indexing to implement `cross_entropy`.\n\n\n"}, {"cell_type": "code", "metadata": {}, "source": "def cross_entropy(logits: Tensor, true_labels: Tensor) -> Tensor:\n    \"\"\"Like torch.nn.functional.cross_entropy with reduction='none'.\n\n    logits: shape (batch, classes)\n    true_labels: shape (batch,). Each element is the index of the correct label in the logits.\n\n    Return: shape (batch, ) containing the per-example loss.\n    \"\"\"\n    pass\n\n\nif MAIN:\n    w1d3_test.test_cross_entropy(Tensor, cross_entropy)\n\n", "outputs": []}, {"cell_type": "markdown", "metadata": {}, "source": "\n## Build Your Own `no_grad`\n\nThe last thing our backpropagation system needs is the ability to turn it off completely like `torch.no_grad`.\n\nImplement the `NoGrad` context manager so that it reads and writes the `grad_tracking_enabled` flag from the top of the file. Update your `tensor_func` inside `wrap_forward_fn` to check the flag. In general, using mutable global variables is not ideal because multiple threads will be a problem, but we will leave that for another day.\n\nTip: to write to a global variable, you need to use the `global` keyword as in `global grad_tracking_enabled`, otherwise Python thinks that you want to create a new local variable.\n\n\n"}, {"cell_type": "code", "metadata": {}, "source": "class NoGrad:\n    \"\"\"Context manager that disables grad inside the block. Like torch.no_grad.\"\"\"\n\n    was_enabled: bool\n\n    def __enter__(self):\n        pass\n\n    def __exit__(self, type, value, traceback):\n        pass\n\n\nif MAIN:\n    w1d3_test.test_no_grad(Tensor, NoGrad)\n    w1d3_test.test_no_grad_nested(Tensor, NoGrad)\n\n", "outputs": []}, {"cell_type": "markdown", "metadata": {}, "source": "\n## Training Your Network\n\nTomorrow is optimizer and training day where you'll be investigating SGD in much more depth and writing your own training loop, so we'll provide a minimal version of these today as well as the data loading code.\n\n\n"}, {"cell_type": "code", "metadata": {}, "source": "def visualize(dataloader):\n    \"\"\"Call this if you want to see some of your data.\"\"\"\n    plt.figure(figsize=(12, 12))\n    (sample, sample_labels) = next(iter(dataloader))\n    for i in range(10):\n        plt.subplot(5, 5, i + 1)\n        plt.xticks([])\n        plt.yticks([])\n        plt.imshow(sample[i, 0], cmap=plt.cm.binary)\n    plt.show()\n\n\nif MAIN:\n    subsample = 20 if IS_CI else None\n    (train_loader, test_loader) = w1d3_utils.get_mnist(subsample)\n\n\nclass SGD:\n    def __init__(self, params: Iterable[Parameter], lr: float):\n        \"\"\"Vanilla SGD with no additional features.\"\"\"\n        self.params = list(params)\n        self.lr = lr\n        self.b = [None for _ in self.params]\n\n    def zero_grad(self) -> None:\n        for p in self.params:\n            p.grad = None\n\n    def step(self) -> None:\n        with NoGrad():\n            for (i, p) in enumerate(self.params):\n                assert isinstance(p.grad, Tensor)\n                p.add_(p.grad, -self.lr)\n\n\ndef train(model, train_loader, optimizer, epoch):\n    for (batch_idx, (data, target)) in enumerate(train_loader):\n        data = Tensor(data.numpy())\n        target = Tensor(target.numpy())\n        optimizer.zero_grad()\n        output = model(data)\n        loss = cross_entropy(output, target).sum() / len(output)\n        loss.backward()\n        optimizer.step()\n        if batch_idx % 50 == 0:\n            print(\n                \"Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}\".format(\n                    epoch,\n                    batch_idx * len(data),\n                    len(train_loader.dataset),\n                    100.0 * batch_idx / len(train_loader),\n                    loss.item(),\n                )\n            )\n\n\ndef test(model, test_loader):\n    test_loss = 0\n    correct = 0\n    with NoGrad():\n        for (data, target) in test_loader:\n            data = Tensor(data.numpy())\n            target = Tensor(target.numpy())\n            output = model(data)\n            test_loss += cross_entropy(output, target).sum().item()\n            pred = output.argmax(dim=1, keepdim=True)\n            correct += (pred == target.reshape(pred.shape)).sum().item()\n    test_loss /= len(test_loader.dataset)\n    print(\n        \"\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n\".format(\n            test_loss, correct, len(test_loader.dataset), 100.0 * correct / len(test_loader.dataset)\n        )\n    )\n\n", "outputs": []}, {"cell_type": "markdown", "metadata": {}, "source": "\n### Training Loop\n\nTo finish the day, let's see if everything works correctly and our MLP learns to classify MNIST. It's normal to encounter some bugs and glitches at this point - just go back and fix them until everything runs.\n\nMy MLP was able to reach 88% accuracy after 5 epochs (around 15 seconds).\n\n\n"}, {"cell_type": "code", "metadata": {}, "source": "if MAIN:\n    num_epochs = 5\n    model = MLP()\n    start = time.time()\n    optimizer = SGD(model.parameters(), 0.01)\n    for epoch in range(num_epochs):\n        train(model, train_loader, optimizer, epoch)\n        test(model, test_loader)\n        optimizer.step()\n    print(f\"Completed in {time.time() - start: .2f}s\")\n\n", "outputs": []}, {"cell_type": "markdown", "metadata": {}, "source": "\n## Bonus\n\nCongratulations on finishing the day's main content!\n\n### In-Place Operation Warnings\n\nThe most severe issue with our current system is that it can silently compute the wrong gradients when in-place operations are used. Have a look at how [PyTorch handles it](https://pytorch.org/docs/stable/notes/autograd.html#in-place-operations-with-autograd) and implement a similar system yourself so that it either computes the right gradients, or raises a warning.\n\n### In-Place ReLU\n\nInstead of implementing ReLU in terms of maximum, implement your own forward and backward functions that support `inplace=True`.\n\n### Backward for einsum\n\nWrite the backward pass for your equivalent of `torch.einsum`.\n\n### Reuse of Module during forward\n\nConsider the following MLP, where the same `nn.ReLU` instance is used twice in the forward pass. Without running the code, explain whether this works correctly or not with reference to the specifics of your implementation.\n\n"}, {"cell_type": "code", "metadata": {}, "source": "\nclass MyModule(Module):\n    def __init__(self):\n        super().__init__()\n        self.linear1 = Linear(28*28, 64)\n        self.linear2 = Linear(64, 64)\n        self.linear3 = Linear(64, 10)\n        self.relu = ReLU()\n\n    def forward(self, x):\n        x = self.relu(self.linear1(x))\n        x = self.relu(self.linear2(x))\n        return self.linear3(x)\n", "outputs": []}, {"cell_type": "markdown", "metadata": {}, "source": "\n### ResNet Support\n\nMake a list of the features that would need to be implemented to support ResNet inference, and training. It will probably take too long to do all of them, but pick some interesting features to start implementing.\n\n### Central Difference Checking\n\nWrite a function that compares the gradients from your backprop to a central difference method. See [Wikipedia](https://en.wikipedia.org/wiki/Finite_difference) for more details.\n\n### Non-Differentiable Function Support\n\nYour `Tensor` does not currently support equivalents of `torch.all`, `torch.any`, `torch.floor`, `torch.less`, etc. which are non-differentiable functions of Tensors. Implement them so that they are usable in computational graphs, but gradients shouldn't flow through them (their contribution is zero).\n\n### Differentiation wrt Keyword Arguments\n\nIn the real PyTorch, you can sometimes pass tensors as keyword arguments and differentiation will work, as in `t.add(other=t.tensor([3,4]), input=t.tensor([1,2]))`. In other similar looking cases like `t.dot`, it raises an error that the argument must be passed positionally. Decide on a desired behavior in your system and implement and test it.\n\n### torch.stack\n\nSo far we've registered a separate backwards for each input argument that could be a Tensor. This is problematic if the function can take any number of tensors like torch.stack or numpy.stack. Think of and implement the backward function for stack. It may require modification to your other code.\n"}], "metadata": {"kernelspec": {"display_name": "Python 3", "language": "python", "name": "python3"}, "language_info": {"codemirror_mode": {"name": "ipython", "version": 3}, "file_extension": ".py", "mimetype": "text/x-python", "name": "python", "nbconvert_exporter": "python", "pygments_lexer": "ipython3", "version": "3.9.15"}}, "nbformat": 4, "nbformat_minor": 4}